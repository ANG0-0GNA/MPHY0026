{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laparoscopic Liver Surgery Simulation\n",
    "\n",
    "In this notebook, a simulation is conducted, to illustrate the potential accuracy of a laparoscopic liver surgery system.\n",
    "\n",
    "Aim: To simulate\n",
    "\n",
    "![System Diagram](lap_liver_sim_diagram.jpg \"System Diagram\")\n",
    "\n",
    "and see the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jupyter notebook sets the cwd to the folder containing the notebook.\n",
    "# So, you want to add the root of the project to the sys path, so modules load correctly.\n",
    "import sys\n",
    "sys.path.append(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All imports.\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import sksurgeryopencvpython as cvpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_rigid_body_parameters(matrix):\n",
    "    t = matrix[0:3, 3]\n",
    "    r = matrix[0:3, 0:3]\n",
    "    r = R.from_matrix(r)\n",
    "    euler = r.as_euler('zyx', degrees=True)\n",
    "    return [euler[0], euler[1], euler[2], t[0], t[1], t[2]]\n",
    "\n",
    "def rigid_body_parameters_to_matrix(params):\n",
    "    matrix = np.eye(4)\n",
    "    r = (R.from_euler('zyx', [params[0], params[1], params[2]], degrees=True)).as_matrix()\n",
    "    matrix[0:3, 0:3] = r\n",
    "    matrix[0][3] = params[3]\n",
    "    matrix[1][3] = params[4]\n",
    "    matrix[2][3] = params[5]\n",
    "    return matrix\n",
    "\n",
    "def convert_camera_point_to_world(point, camera_to_marker, marker_to_world):\n",
    "    return marker_to_world @ camera_to_marker @ point\n",
    "\n",
    "def convert_4x1_to_1x1x3(p_41):\n",
    "    p_113 = np.zeros((1,1,3))\n",
    "    p_113[0][0][0] = p_41[0][0]\n",
    "    p_113[0][0][1] = p_41[1][0]\n",
    "    p_113[0][0][2] = p_41[2][0]\n",
    "    return p_113\n",
    "\n",
    "def convert_1x2_to_1x1x2(p_12):\n",
    "    p_112 = np.zeros((1,1,2))\n",
    "    p_112[0][0][0] = p_12[0]\n",
    "    p_112[0][0][1] = p_12[1] \n",
    "    return p_112\n",
    "\n",
    "def project_camera_point_to_image(point, intrinsics, distortion):\n",
    "    rvec = np.zeros((1,3))\n",
    "    tvec = np.zeros((1,3))\n",
    "    image_points, jacobian = cv2.projectPoints(convert_4x1_to_1x1x3(point), rvec, tvec, intrinsics, distortion)\n",
    "    return image_points[0][0] # returns a list\n",
    "           \n",
    "def convert_left_camera_to_right_camera(point, left_to_right):\n",
    "    return left_to_right @ point\n",
    "\n",
    "def triangulate_points_to_3d(left_point, left_intrinsic, left_distortion, right_point, right_intrinsic, right_distortion, left_to_right):\n",
    "    left_point_undistorted = cv2.undistortPoints(convert_1x2_to_1x1x2(left_point), left_intrinsic, left_distortion, None, left_intrinsic)\n",
    "    right_point_undistorted = cv2.undistortPoints(convert_1x2_to_1x1x2(right_point), right_intrinsic, right_distortion, None, right_intrinsic)\n",
    "    image_points = np.zeros((1,4))\n",
    "    image_points[0][0] = left_point_undistorted[0][0][0]\n",
    "    image_points[0][1] = left_point_undistorted[0][0][1]\n",
    "    image_points[0][2] = right_point_undistorted[0][0][0]\n",
    "    image_points[0][3] = right_point_undistorted[0][0][1]\n",
    "    reconstructed = cvpy.triangulate_points_using_hartley(image_points,\n",
    "                                                          left_intrinsic,\n",
    "                                                          right_intrinsic,\n",
    "                                                          left_to_right[0:3, 0:3],\n",
    "                                                          left_to_right[0:3, 3]\n",
    "                                                          )\n",
    "    result = np.ones((4,1))\n",
    "    result[0][0] = reconstructed[0][0]\n",
    "    result[1][0] = reconstructed[0][1]\n",
    "    result[2][0] = reconstructed[0][2]\n",
    "    return result                                   \n",
    "\n",
    "def initialise_gold_standard(cam_x, cam_y, cam_z):\n",
    "    point_in_left_camera_space = np.ones((4,1))\n",
    "    point_in_left_camera_space[0][0] = cam_x\n",
    "    point_in_left_camera_space[1][0] = cam_y\n",
    "    point_in_left_camera_space[2][0] = cam_z\n",
    "    point_in_right_camera_space = convert_left_camera_to_right_camera(point_in_left_camera_space, left_to_right)\n",
    "\n",
    "    left_image_point = project_camera_point_to_image(point_in_left_camera_space, left_intrinsics, left_distortion)\n",
    "    right_image_point = project_camera_point_to_image(point_in_right_camera_space, right_intrinsics, right_distortion)\n",
    "    reconstructed = triangulate_points_to_3d(left_image_point, left_intrinsics, left_distortion, right_image_point, right_intrinsics, right_distortion, left_to_right)\n",
    "\n",
    "    assert np.allclose(point_in_left_camera_space, reconstructed)\n",
    "\n",
    "    gold_standard_world_point = convert_camera_point_to_world(point_in_left_camera_space, camera_to_marker, marker_to_world)\n",
    "    return point_in_left_camera_space, gold_standard_world_point, left_image_point, right_image_point\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load reference data.\n",
    "\n",
    "\n",
    "This data comes from the SmartLiver system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Camera intrinsic calibration\n",
    "left_intrinsics = np.loadtxt('lap_liver_left_intrinsics.txt')\n",
    "left_distortion = np.loadtxt('lap_liver_left_distortion.txt')\n",
    "right_intrinsics = np.loadtxt('lap_liver_right_intrinsics.txt')\n",
    "right_distortion = np.loadtxt('lap_liver_right_distortion.txt')\n",
    "\n",
    "# Hand-eye or, marker-to-camera\n",
    "marker_to_camera = np.loadtxt('lap_liver_sim_marker_to_camera.txt')\n",
    "camera_to_marker = np.linalg.inv(marker_to_camera)\n",
    "\n",
    "# Its a stereo laparoscope, so separation between right and left camera.\n",
    "left_to_right = np.loadtxt('lap_liver_sim_l2r.txt')\n",
    "\n",
    "# And it's tracked, so, the marker to world transform.\n",
    "marker_to_world = np.loadtxt('lap_liver_sim_marker_to_world.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Simulation Parameters\n",
    "\n",
    "These parameters are the ones that define the simulation. As we vary them within certain ranges, we will see how much they change the accuracy of the result. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First parameterise the main transformations. \n",
    "# The order is: rx, ry, rx, tx, ty, tz, where rotations are in degrees and translations in millimetres.\n",
    "marker2camera = extract_rigid_body_parameters(marker_to_camera)\n",
    "marker2world = extract_rigid_body_parameters(marker_to_world)\n",
    "left2right = extract_rigid_body_parameters(left_to_right)\n",
    "\n",
    "# Create some fixed parameters\n",
    "image_size = (1920, 1080) # width, height, in pixels\n",
    "distance_from_camera = 75 # millimetres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Gold Standard\n",
    "\n",
    "We need to define the thing we are measuring or evaluating. Imagine we are trying to assess the accuracy of triangulating a point that is in front of the camera, and correctly positioning it in world space. So, first, generate a point in camera coordinates, project to 2D left and right images, triangulate back to 3D, to check we get the same point, and convert to world space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting gold standard:\n",
      "Left camera point:[[ 5.]\n",
      " [10.]\n",
      " [75.]\n",
      " [ 1.]]\n",
      "World point:[[ 1.02579661e+02]\n",
      " [ 2.55747093e+00]\n",
      " [-1.76820496e+03]\n",
      " [ 1.00000000e+00]]\n",
      "Left image point:[904.48111684 790.14748833]\n",
      "Right image point:[1028.96090457  791.28608348]\n"
     ]
    }
   ],
   "source": [
    "gold_left_camera_point, gold_world_point, gold_left_image_point, gold_right_image_point = initialise_gold_standard(5, 10, distance_from_camera)\n",
    "\n",
    "print(\"Starting gold standard:\")\n",
    "print(\"Left camera point:\" + str(gold_left_camera_point))\n",
    "print(\"World point:\" + str(gold_world_point))\n",
    "print(\"Left image point:\" + str(gold_left_image_point))\n",
    "print(\"Right image point:\" + str(gold_right_image_point))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mphy0026",
   "language": "python",
   "name": "mphy0026"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
